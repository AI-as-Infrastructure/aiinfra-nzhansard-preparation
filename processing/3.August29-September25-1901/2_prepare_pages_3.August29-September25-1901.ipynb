{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat <page> tags to match AU and UK.\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define session variable\n",
    "session = '3.August29-September25-1901'\n",
    "\n",
    "# Define subdirectory path\n",
    "subdirectory_path = '../../output/sessions'\n",
    "\n",
    "# Construct the directory path dynamically\n",
    "directory = os.path.join(subdirectory_path, session)\n",
    "\n",
    "def replace_text_in_files(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            # Replace <page:123> with <page>123</page>\n",
    "            new_content = re.sub(r'<page:(\\d+)>', r'<page>\\1</page>', content)\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(new_content)\n",
    "\n",
    "# Call the function with the dynamically constructed directory\n",
    "replace_text_in_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for this volume, to manage inconsistencies between the page numbers of the Google pdf and the Hathi PDF. This can be considered a bug. The best solution would be to re-transcribe (produce new .json source files).\n",
    "\n",
    "def get_last_page_numbers(directory):\n",
    "    last_page_numbers = {}\n",
    "\n",
    "    # Sort filenames based on the numeric part at the beginning\n",
    "    filenames = sorted(os.listdir(directory), key=lambda x: int(re.findall(r'^\\d+', x)[0]) if re.findall(r'^\\d+', x) else float('inf'))\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r') as file:\n",
    "                content = file.read()\n",
    "\n",
    "            # Find all <page> tags\n",
    "            page_tags = re.findall(r'<page>\\d+</page>', content)\n",
    "            if page_tags:\n",
    "                # Extract the last page number\n",
    "                last_page_number = int(re.findall(r'\\d+', page_tags[-1])[0])\n",
    "                last_page_numbers[filename] = last_page_number\n",
    "\n",
    "    return last_page_numbers\n",
    "\n",
    "def reset_page_tags(directory, last_page_numbers):\n",
    "    page_number = 1\n",
    "    previous_last_page_number = None\n",
    "    previous_filename = None\n",
    "\n",
    "    # Sort filenames based on the numeric part at the beginning\n",
    "    filenames = sorted(os.listdir(directory), key=lambda x: int(re.findall(r'^\\d+', x)[0]) if re.findall(r'^\\d+', x) else float('inf'))\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r') as file:\n",
    "                content = file.read()\n",
    "\n",
    "            # Find all <page> tags\n",
    "            page_tags = re.findall(r'<page>\\d+</page>', content)\n",
    "\n",
    "            if page_tags:\n",
    "                first_page_number = int(re.findall(r'\\d+', page_tags[0])[0])\n",
    "\n",
    "                if previous_last_page_number is not None and first_page_number == previous_last_page_number:\n",
    "                    # Retrieve the updated last page number from the previous file\n",
    "                    if previous_filename:\n",
    "                        previous_filepath = os.path.join(directory, previous_filename)\n",
    "                        with open(previous_filepath, 'r') as prev_file:\n",
    "                            prev_content = prev_file.read()\n",
    "                        prev_page_tags = re.findall(r'<page>\\d+</page>', prev_content)\n",
    "                        if prev_page_tags:\n",
    "                            new_last_page_number = int(re.findall(r'\\d+', prev_page_tags[-1])[0])\n",
    "                            # Start page numbering using new_last_page_number\n",
    "                            page_number = new_last_page_number\n",
    "\n",
    "            # Replace each <page> tag with the new sequence number\n",
    "            for tag in page_tags:\n",
    "                new_tag = f'<page>{page_number}</page>'\n",
    "                content = content.replace(tag, new_tag, 1)\n",
    "                page_number += 1\n",
    "\n",
    "            # Write the modified content back to the file\n",
    "            with open(filepath, 'w') as file:\n",
    "                file.write(content)\n",
    "\n",
    "            # Update the previous last page number and filename\n",
    "            if page_tags:\n",
    "                previous_last_page_number = int(re.findall(r'\\d+', page_tags[-1])[0])\n",
    "                previous_filename = filename\n",
    "\n",
    "# First pass to get the last page numbers\n",
    "last_page_numbers = get_last_page_numbers(directory)\n",
    "\n",
    "# Second pass to reset the page tags\n",
    "reset_page_tags(directory, last_page_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "process_file() missing 2 required positional arguments: 'delete_unwanted' and 'delete_before_page'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     60\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subdirectory_path, filename)\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhathi_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhathi_starting_page\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: process_file() missing 2 required positional arguments: 'delete_unwanted' and 'delete_before_page'"
     ]
    }
   ],
   "source": [
    "# Define the hathi_starting_page. This is the page in the Hathi Trust Google PDF that corresponds to the first page of Hansard in the original digitized source. It is used to concatenate the url to the Hathi Trust source.\n",
    "\n",
    "hathi_id = 'uc1.32106019788253'\n",
    "hathi_starting_page = 21  \n",
    "\n",
    "# Construct the path to the subdirectory\n",
    "subdirectory_path = os.path.join('../../output/sessions', session)  # 'session' is already defined\n",
    "\n",
    "# Initialize the current Hathi page number\n",
    "current_hathi_page = hathi_starting_page\n",
    "\n",
    "def process_file(file_path, hathi_id, hathi_starting_page):\n",
    "    global current_hathi_page\n",
    "    unwanted_deleted = False\n",
    "\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "\n",
    "    # Read the content of the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()    \n",
    " \n",
    "    # Split the content by lines\n",
    "    lines = content.split('\\n')\n",
    "    new_lines = []\n",
    "    \n",
    "    # Iterate over each line and process <page> tags\n",
    "    for line in lines:\n",
    "        page_match = re.match(r'<page>(\\d+)</page>', line)\n",
    "        \n",
    "        if page_match:\n",
    "            # Keep the original page number\n",
    "            page_number = int(page_match.group(1))\n",
    "            new_lines.append(f'<page>{page_number}</page>')\n",
    "            \n",
    "            # Calculate the HathiTrust page number based on the delta\n",
    "            hathi_page_number = hathi_starting_page + (page_number - 1)\n",
    "            url = f'https://babel.hathitrust.org/cgi/pt?id={hathi_id}&seq={hathi_page_number}'\n",
    "            new_lines.append(f'<url>{url}</url>')\n",
    "            print(f\"Updated line: <page>{page_number}</page> and <url>{url}</url>\")\n",
    "        else:\n",
    "            url_match = re.match(r'<url>https://babel.hathitrust.org/cgi/pt\\?id=.*&seq=\\d+</url>', line)\n",
    "            if url_match:\n",
    "                # Skip the existing URL line\n",
    "                continue\n",
    "            else:\n",
    "                new_lines.append(line)\n",
    "    \n",
    "    # Join the new lines to form the updated content\n",
    "    updated_content = '\\n'.join(new_lines)\n",
    "    \n",
    "    # Write the updated content to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(updated_content)\n",
    "\n",
    "    print(f\"Finished processing file: {file_path}\")\n",
    "\n",
    "# Iterate over each file in the subdirectory\n",
    "for filename in sorted(os.listdir(subdirectory_path)):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(subdirectory_path, filename)\n",
    "        process_file(file_path, hathi_id, hathi_starting_page)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
