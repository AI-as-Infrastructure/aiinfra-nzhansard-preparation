{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook could be added to prepare_ocr_sessions but is included separately because it is a distinct step in the processing pipeline that requires configuration per source pdf (in both cells).\n",
    "\n",
    "Documentation, to set session folder for processing and Hathi ID for url references:\n",
    "- session = '1.July01-July26-1901' \n",
    "- hathi_id = 'uc1.32106019788238'\n",
    "- starting_page = 1\n",
    "- session = '2.July30-August28-1901' \n",
    "- hathi_id = 'uc1.32106019788246'\n",
    "- starting_page = 25\n",
    "- session = '3.August29-September25-1901'\n",
    "- hathi_id = 'uc1.32106019788253'\n",
    "- starting_page = 17\n",
    "- session = '4.September26-November07-1901'\n",
    "- hathi_id = 'uc1.32106019788261'\n",
    "- starting_page = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat <page> tags to match AU and UK.\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define session variable\n",
    "session = '1.July01-July26-1901'\n",
    "\n",
    "# Define subdirectory path\n",
    "subdirectory_path = 'output/sessions'\n",
    "\n",
    "# Construct the directory path dynamically\n",
    "directory = os.path.join(subdirectory_path, session)\n",
    "\n",
    "def replace_text_in_files(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            # Replace <page:123> with <page>123</page>\n",
    "            new_content = re.sub(r'<page:(\\d+)>', r'<page>\\1</page>', content)\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(new_content)\n",
    "\n",
    "# Call the function with the dynamically constructed directory\n",
    "replace_text_in_files(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: output/sessions/1.July01-July26-1901/1-Monday, 1st July, 1901.txt\n",
      "Finished processing file: output/sessions/1.July01-July26-1901/1-Monday, 1st July, 1901.txt\n",
      "Processing file: output/sessions/1.July01-July26-1901/2-Tuesday, 2nd July, 1901.txt\n",
      "Finished processing file: output/sessions/1.July01-July26-1901/2-Tuesday, 2nd July, 1901.txt\n"
     ]
    }
   ],
   "source": [
    "# Correct page numbers so they refer to the Hansard source rather than the Google pdf, and add the corresponding URL for the Hathi online version (see documentation in first cell).\n",
    "\n",
    "# Define the hathi_starting_page, using the documentation in the cell above. This is the page in the Hathi Trust Google PDF that corresponds to the first page of Hansard in the original digitized source.\n",
    "hathi_id = 'uc1.32106019788238'\n",
    "hathi_starting_page = 29  \n",
    "delete_unwanted = 'No'  # Option to delete unwanted content before a certain page\n",
    "delete_before_page = 31  # Define the page before which all content will be deleted\n",
    "\n",
    "# Construct the path to the subdirectory\n",
    "subdirectory_path = os.path.join('output/sessions', session)  # 'session' is already defined\n",
    "\n",
    "def process_file(file_path, hathi_id, hathi_starting_page, delete_unwanted, delete_before_page, starting_page_number):\n",
    "    unwanted_deleted = False\n",
    "    local_page_number = starting_page_number\n",
    "\n",
    "    print(f\"Processing file: {file_path}\")\n",
    "\n",
    "    # Read the content of the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # If delete_unwanted is set to 'Yes' and unwanted content has not been deleted yet\n",
    "    if delete_unwanted == 'Yes' and not unwanted_deleted:\n",
    "        start_index = content.find(f'<page>{delete_before_page}</page>')\n",
    "        if start_index != -1:\n",
    "            content = content[start_index:]\n",
    "            unwanted_deleted = True\n",
    "            local_page_number = starting_page_number  # Reset the local page number\n",
    "            print(f\"Unwanted content deleted. Reset local_page_number to {local_page_number}\")\n",
    "    \n",
    "    # Split the content by lines\n",
    "    lines = content.split('\\n')\n",
    "    new_lines = []\n",
    "    \n",
    "    # Iterate over each line and process <page> tags\n",
    "    for line in lines:\n",
    "        page_match = re.match(r'<page>(\\d+)</page>', line)\n",
    "        \n",
    "        if page_match:\n",
    "            # Use the local_page_number instead of the original page number\n",
    "            url_page_number = local_page_number + hathi_starting_page - 1\n",
    "            new_lines.append(f'<page>{local_page_number}</page>')\n",
    "            url = f'<url>https://babel.hathitrust.org/cgi/pt?id={hathi_id}&seq={url_page_number}</url>'\n",
    "            new_lines.append(url)\n",
    "            print(f\"Updated line: <page>{local_page_number}</page> and {url}\")\n",
    "            local_page_number += 1\n",
    "        else:\n",
    "            url_match = re.match(r'<url>https://babel.hathitrust.org/cgi/pt\\?id=.*&seq=\\d+</url>', line)\n",
    "            if url_match:\n",
    "                # Skip the existing URL line\n",
    "                continue\n",
    "            else:\n",
    "                new_lines.append(line)\n",
    "    \n",
    "    # Join the new lines to form the updated content\n",
    "    updated_content = '\\n'.join(new_lines)\n",
    "    \n",
    "    # Write the updated content to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(updated_content)\n",
    "\n",
    "    print(f\"Finished processing file: {file_path}\")\n",
    "\n",
    "# Define the starting page numbers for each session file\n",
    "starting_page_numbers = {\n",
    "    '1-Monday, 1st July, 1901.txt': 1,\n",
    "    '2-Tuesday, 2nd July, 1901.txt': 7,\n",
    "    # Add more files and their starting page numbers as needed\n",
    "}\n",
    "\n",
    "# Iterate over each file in the subdirectory\n",
    "for filename in sorted(os.listdir(subdirectory_path)):\n",
    "    if filename.endswith('.txt') and filename in starting_page_numbers:\n",
    "        file_path = os.path.join(subdirectory_path, filename)\n",
    "        starting_page_number = starting_page_numbers[filename]\n",
    "        process_file(file_path, hathi_id, hathi_starting_page, delete_unwanted, delete_before_page, starting_page_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
